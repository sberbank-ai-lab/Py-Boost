{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "from py_boost import GradientBoosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 s, sys: 1.57 s, total: 3.72 s\n",
      "Wall time: 831 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=10, random_state=42)\n",
    "X = X.astype(np.float32)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:46] Stdout logging level is INFO.\n",
      "[13:41:46] GDBT train starts. Max iter 1000, early stopping rounds 200\n",
      "[13:41:47] Iter 0; Sample 0, R2_score = 0.07438634372555475; \n",
      "[13:41:48] Iter 100; Sample 0, R2_score = 0.9877549755188597; \n",
      "[13:41:49] Iter 200; Sample 0, R2_score = 0.9906494384457265; \n",
      "[13:41:50] Iter 300; Sample 0, R2_score = 0.9909321804947996; \n",
      "[13:41:51] Iter 400; Sample 0, R2_score = 0.9910298856821315; \n",
      "[13:41:52] Iter 500; Sample 0, R2_score = 0.9911125353816248; \n",
      "[13:41:53] Iter 600; Sample 0, R2_score = 0.9911402694434043; \n",
      "[13:41:54] Iter 700; Sample 0, R2_score = 0.9911714811053071; \n",
      "[13:41:55] Iter 800; Sample 0, R2_score = 0.9911579905713459; \n",
      "[13:41:57] Iter 900; Sample 0, R2_score = 0.9911550964716098; \n",
      "[13:41:57] Early stopping at iter 922, best iter 722, best_score 0.9911740777172078\n",
      "CPU times: user 12.7 s, sys: 1.16 s, total: 13.9 s\n",
      "Wall time: 12.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f138029fca0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', 'r2_score',\n",
    "                         ntrees=1000, lr=.1, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=6)\n",
    "model.fit(X, y[:, 0], \n",
    "          eval_sets = [\n",
    "              {'X': X_test, 'y': y_test[:, 0]}, \n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:41:09] Stdout logging level is INFO2.\n",
      "[13:41:09] GDBT train starts. Max iter 2000, early stopping rounds 200\n",
      "[13:41:09] Iter 0; Sample 0, R2_score = 0.010256408618130087;  Sample 1, R2_score = 0.009789836832384413; \n",
      "[13:41:12] Iter 100; Sample 0, R2_score = 0.6237097084436416;  Sample 1, R2_score = 0.5949179752753461; \n",
      "[13:41:15] Iter 200; Sample 0, R2_score = 0.8299463376505928;  Sample 1, R2_score = 0.7972185467858299; \n",
      "[13:41:18] Iter 300; Sample 0, R2_score = 0.9177264578290203;  Sample 1, R2_score = 0.8887807155839937; \n",
      "[13:41:21] Iter 400; Sample 0, R2_score = 0.9584496629748219;  Sample 1, R2_score = 0.9344900582799159; \n",
      "[13:41:24] Iter 500; Sample 0, R2_score = 0.9780890043254086;  Sample 1, R2_score = 0.9586314490380425; \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', 'r2', \n",
    "                         ntrees=2000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=8)\n",
    "model.fit(X, y, \n",
    "          eval_sets = [\n",
    "              {'X': X, 'y': y}, \n",
    "              {'X': X_test, 'y': y_test}\n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; Sample 0, score = 179.12324045227626;  Sample 1, score = 178.5527616037698; \n",
      "Iter 100; Sample 0, score = 99.5956700642039;  Sample 1, score = 103.33447884698649; \n",
      "Iter 200; Sample 0, score = 61.255816755925096;  Sample 1, score = 67.87146591156528; \n",
      "Iter 300; Sample 0, score = 40.146739327207335;  Sample 1, score = 48.50921889753441; \n",
      "Iter 400; Sample 0, score = 27.544164811371594;  Sample 1, score = 36.93368816492511; \n",
      "Iter 500; Sample 0, score = 19.651848143801097;  Sample 1, score = 29.642689281600365; \n",
      "Iter 600; Sample 0, score = 14.630266789584756;  Sample 1, score = 24.937504836623113; \n",
      "Iter 700; Sample 0, score = 11.456814563574161;  Sample 1, score = 21.862548617819463; \n",
      "Iter 800; Sample 0, score = 9.470113084280912;  Sample 1, score = 19.825650839050073; \n",
      "Iter 900; Sample 0, score = 8.25229718448769;  Sample 1, score = 18.468577195323558; \n",
      "Iter 1000; Sample 0, score = 7.49936808439699;  Sample 1, score = 17.547041370324568; \n",
      "Iter 1100; Sample 0, score = 7.025223071153005;  Sample 1, score = 16.921672976436323; \n",
      "Iter 1200; Sample 0, score = 6.711501901554081;  Sample 1, score = 16.49632632240697; \n",
      "Iter 1300; Sample 0, score = 6.488302143740051;  Sample 1, score = 16.208361782104312; \n",
      "Iter 1400; Sample 0, score = 6.313250855981977;  Sample 1, score = 16.005885192802364; \n",
      "Iter 1500; Sample 0, score = 6.163625018511346;  Sample 1, score = 15.864897415012772; \n",
      "Iter 1600; Sample 0, score = 6.031574763599167;  Sample 1, score = 15.765734526101348; \n",
      "Iter 1700; Sample 0, score = 5.910348840760711;  Sample 1, score = 15.69597908242985; \n",
      "Iter 1800; Sample 0, score = 5.790057832084124;  Sample 1, score = 15.646224552347574; \n",
      "Iter 1900; Sample 0, score = 5.672053855863118;  Sample 1, score = 15.609277029660676; \n",
      "Iter 1999; Sample 0, score = 5.54940570003387;  Sample 1, score = 15.580296687981457; \n",
      "CPU times: user 4min 12s, sys: 4.68 s, total: 4min 17s\n",
      "Wall time: 4min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f8f520ec6a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', \n",
    "                         ntrees=2000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=8, target_splitter='OneVsAll')\n",
    "model.fit(X, y, \n",
    "          eval_sets = [\n",
    "              {'X': X, 'y': y}, \n",
    "              {'X': X_test, 'y': y_test}\n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_boost.sampling.target_splitter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0; Sample 0, score = 179.2460777763383;  Sample 1, score = 178.67696388647525; \n",
      "Iter 100; Sample 0, score = 108.08098298391276;  Sample 1, score = 111.88127933113428; \n",
      "Iter 200; Sample 0, score = 69.64128866636518;  Sample 1, score = 76.20619580333553; \n",
      "Iter 300; Sample 0, score = 46.600844949160475;  Sample 1, score = 54.78188608355994; \n",
      "Iter 400; Sample 0, score = 31.954479946143096;  Sample 1, score = 41.1110594490837; \n",
      "Iter 500; Sample 0, score = 22.49775869073082;  Sample 1, score = 32.23539407266256; \n",
      "Iter 600; Sample 0, score = 16.444437587243776;  Sample 1, score = 26.472972072640065; \n",
      "Iter 700; Sample 0, score = 12.6941105297289;  Sample 1, score = 22.763459655435106; \n",
      "Iter 800; Sample 0, score = 10.405959311366699;  Sample 1, score = 20.3429295053605; \n",
      "Iter 900; Sample 0, score = 9.036731029616549;  Sample 1, score = 18.741360726529646; \n",
      "Iter 1000; Sample 0, score = 8.229365330541649;  Sample 1, score = 17.68068729977043; \n",
      "Iter 1100; Sample 0, score = 7.735863616925175;  Sample 1, score = 16.960970829213412; \n",
      "Iter 1200; Sample 0, score = 7.423168894994463;  Sample 1, score = 16.478181226337508; \n",
      "Iter 1300; Sample 0, score = 7.202008494761571;  Sample 1, score = 16.149500287411357; \n",
      "Iter 1400; Sample 0, score = 7.041360295236946;  Sample 1, score = 15.925099129933018; \n",
      "Iter 1500; Sample 0, score = 6.911106690685191;  Sample 1, score = 15.770587884827744; \n",
      "Iter 1600; Sample 0, score = 6.7892816228108686;  Sample 1, score = 15.653603619994493; \n",
      "Iter 1700; Sample 0, score = 6.68142195920123;  Sample 1, score = 15.56722051335154; \n",
      "Iter 1800; Sample 0, score = 6.578163718932074;  Sample 1, score = 15.504205658074813; \n",
      "Iter 1900; Sample 0, score = 6.478371097324976;  Sample 1, score = 15.457452707686107; \n",
      "Iter 1999; Sample 0, score = 6.378677196110137;  Sample 1, score = 15.41926416979333; \n",
      "CPU times: user 1min 10s, sys: 4.97 s, total: 1min 15s\n",
      "Wall time: 1min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f8f5230a280>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', \n",
    "                         ntrees=2000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=8, target_splitter=RandomGroupsSplitter(2))\n",
    "model.fit(X, y, \n",
    "          eval_sets = [\n",
    "              {'X': X, 'y': y}, \n",
    "              {'X': X_test, 'y': y_test}\n",
    "          ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
