{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The simpliest usage example of py_boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation (if needed)\n",
    "\n",
    "**Note**: replace cupy-cuda110 with your cuda version!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cupy-cuda110 in /home/user/.local/lib/python3.6/site-packages (9.6.0)\n",
      "Requirement already satisfied: py-boost in /home/user/.local/lib/python3.6/site-packages (0.1.0)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda110) (0.5)\n",
      "Requirement already satisfied: numpy<1.24,>=1.17 in /usr/local/lib/python3.6/dist-packages (from cupy-cuda110) (1.19.5)\n",
      "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.6/dist-packages (from py-boost) (1.1.5)\n",
      "Requirement already satisfied: importlib-metadata<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from py-boost) (1.7.0)\n",
      "Requirement already satisfied: cupy>=9.0.0 in /usr/local/lib/python3.6/dist-packages (from py-boost) (9.4.0)\n",
      "Requirement already satisfied: joblib in /home/user/.local/lib/python3.6/site-packages (from py-boost) (0.15.1)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from py-boost) (0.53.1)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from py-boost) (0.24.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/.local/lib/python3.6/site-packages (from importlib-metadata<2.0,>=1.0->py-boost) (3.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/user/.local/lib/python3.6/site-packages (from pandas>=1->py-boost) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1->py-boost) (2.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/user/.local/lib/python3.6/site-packages (from scikit-learn>=0.22->py-boost) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22->py-boost) (1.5.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->py-boost) (54.0.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /usr/local/lib/python3.6/dist-packages (from numba->py-boost) (0.36.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=1->py-boost) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cupy-cuda110 py-boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Optional: set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "import joblib\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# simple case - just one class is used\n",
    "from py_boost import GradientBoosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of dummy regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.13 s, sys: 1.5 s, total: 3.63 s\n",
      "Wall time: 821 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = make_regression(150000, 100, n_targets=10, random_state=42)\n",
    "X_test, y_test = X[:50000], y[:50000]\n",
    "X, y = X[-50000:], y[-50000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a GBDT model\n",
    "\n",
    "The only argument required here is a loss function. It, together with the input target shape, determines the task type. The loss function can be passed as a Loss instance or using a string alias:\n",
    "\n",
    "* ***'mse'*** for the regression/multitask regression\n",
    "* ***'msle'*** for the regression/multitask regression\n",
    "* ***'bce'*** for the binary/multilabel classification\n",
    "* ***'crossentropy'*** for the multiclassification\n",
    "\n",
    "Training is simply done by calling the .fit metod. Possible argumentsare the following:\n",
    "\n",
    "* ***'X'*** \n",
    "* ***'y'*** \n",
    "* ***'sample_weight'*** \n",
    "* ***'eval_sets'***  \n",
    "A validation set is passed as a list of dicts with possible keys ['X', 'y', 'sample_weight']. Note: if multiple valid sets are passed, the best model is selected using the last one.\n",
    "\n",
    "#### The example below illustrates how to train a simple regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:30] Stdout logging level is INFO.\n",
      "[09:26:30] GDBT train starts. Max iter 100, early stopping rounds 100\n",
      "[09:26:30] Iter 0; Sample 0, rmse = 173.67502218505908; \n",
      "[09:26:30] Iter 10; Sample 0, rmse = 133.1954896923392; \n",
      "[09:26:30] Iter 20; Sample 0, rmse = 107.86651387609845; \n",
      "[09:26:30] Iter 30; Sample 0, rmse = 90.08264442437226; \n",
      "[09:26:30] Iter 40; Sample 0, rmse = 76.44595416433026; \n",
      "[09:26:31] Iter 50; Sample 0, rmse = 65.61115373070031; \n",
      "[09:26:31] Iter 60; Sample 0, rmse = 56.802347598291114; \n",
      "[09:26:31] Iter 70; Sample 0, rmse = 49.57790908462357; \n",
      "[09:26:31] Iter 80; Sample 0, rmse = 43.604359308972406; \n",
      "[09:26:31] Iter 90; Sample 0, rmse = 38.69830902688293; \n",
      "[09:26:31] Iter 99; Sample 0, rmse = 34.9925890975328; \n",
      "CPU times: user 4.23 s, sys: 664 ms, total: 4.89 s\n",
      "Wall time: 3.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f76447a4190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse')\n",
    "\n",
    "model.fit(X, y[:, 0], eval_sets=[{'X': X_test, 'y': y_test[:, 0]},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traininig a GBDT model in a multiregression case\n",
    "\n",
    "Each of built-in loss functions has its own default metric, so metric definition is optional. \n",
    "If you need to specify the evaluation metric, you can pass a Metric instance or use a string alias.\n",
    "\n",
    "#### Default metrics:\n",
    "\n",
    "* ***'rmse'*** is the default for the ***'mse'*** loss\n",
    "* ***'rmsle'*** is the default for the  ***'msle'*** loss\n",
    "* ***'bce'*** is the default for the ***'bce'*** loss\n",
    "* ***'crossentropy'*** is the default for the ***'crossentropy'*** loss\n",
    "\n",
    "#### Non-default metrics:\n",
    "\n",
    "* ***'r2'*** for the regression/multitask regression\n",
    "* ***'auc'*** for the binary classification\n",
    "* ***'accuracy'*** for any classification task\n",
    "* ***'precision'*** for any classification task\n",
    "* ***'recall'*** for any classification task\n",
    "* ***'f1'*** for any classification task\n",
    "\n",
    "It is possible to specify other common GBDT hyperparameters as shown below.\n",
    "\n",
    "#### The following example demonstrates how to train a model for a multioutput regression task (no extra definition needed to switch the task to multioutput one, you just need to pass a multidimensional target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:26:32] Stdout logging level is INFO.\n",
      "[09:26:32] GDBT train starts. Max iter 1000, early stopping rounds 200\n",
      "[09:26:32] Iter 0; Sample 0, R2_score = 0.008384934011665946; \n",
      "[09:26:33] Iter 100; Sample 0, R2_score = 0.5168156713553872; \n",
      "[09:26:35] Iter 200; Sample 0, R2_score = 0.7242761967419419; \n",
      "[09:26:37] Iter 300; Sample 0, R2_score = 0.8326476773549876; \n",
      "[09:26:39] Iter 400; Sample 0, R2_score = 0.8949085297478583; \n",
      "[09:26:40] Iter 500; Sample 0, R2_score = 0.9319644219954142; \n",
      "[09:26:42] Iter 600; Sample 0, R2_score = 0.9546549940950049; \n",
      "[09:26:44] Iter 700; Sample 0, R2_score = 0.9687287866556533; \n",
      "[09:26:45] Iter 800; Sample 0, R2_score = 0.9776128355209428; \n",
      "[09:26:47] Iter 900; Sample 0, R2_score = 0.983291931460586; \n",
      "[09:26:49] Iter 999; Sample 0, R2_score = 0.9869762282705536; \n",
      "CPU times: user 17.7 s, sys: 1.63 s, total: 19.3 s\n",
      "Wall time: 18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7f745a2ddbb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('mse', 'r2_score',\n",
    "                         ntrees=1000, lr=.01, verbose=100, es=200, lambda_l2=1,\n",
    "                         subsample=.8, colsample=.8, min_data_in_leaf=10, min_gain_to_split=0, \n",
    "                         max_bin=256, max_depth=6)\n",
    "\n",
    "model.fit(X, y, eval_sets=[{'X': X_test, 'y': y_test},])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "#### Prediction can be done via calling the .predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 902 ms, sys: 444 ms, total: 1.35 s\n",
      "Wall time: 1.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-239.43956  , -148.27985  , -281.3192   , ..., -142.55777  ,\n",
       "        -214.58322  , -235.33083  ],\n",
       "       [-112.88808  , -116.1815   ,  -64.24356  , ..., -132.47252  ,\n",
       "        -121.00293  ,  -22.776104 ],\n",
       "       [ -32.328655 ,  -52.749233 ,  144.76985  , ...,   21.727789 ,\n",
       "         -20.009361 , -205.19566  ],\n",
       "       ...,\n",
       "       [ -72.1823   ,  138.6279   ,   87.44407  , ...,  229.96695  ,\n",
       "          41.225166 ,   20.167723 ],\n",
       "       [  -6.853402 ,  141.3769   ,  246.19102  , ...,  153.36969  ,\n",
       "         179.23767  ,  208.78542  ],\n",
       "       [ -21.059866 ,   31.169312 ,  168.37772  , ...,   90.69682  ,\n",
       "          19.636633 ,    2.2348657]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction for certan iterations can be done via calling the .predict_staged method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 241 ms, sys: 248 ms, total: 489 ms\n",
      "Wall time: 489 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_staged(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree leaves indicies prediction for certan iterations can be done via calling the .predict_leaves method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 ms, sys: 3.26 ms, total: 22.6 ms\n",
      "Wall time: 21.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 50000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict_leaves(X_test, iterations=[100, 300, 500])\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11, 46,  9],\n",
       "       [54, 46, 28],\n",
       "       [32, 46, 55],\n",
       "       ...,\n",
       "       [54, 53, 18],\n",
       "       [27, 46, 20],\n",
       "       [60, 46, 27]], dtype=uint32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41.,   48.,   39.,   56.,   54.,   50., 5662.,   52.,   53.,\n",
       "         56.,   40.,   52.,   40.,   52.,   30., 5941., 5405.,   39.,\n",
       "         34., 5544.,   43.,   46.,   41.,   65.,   37.,   51.,   45.,\n",
       "         51.,   42.,   52.,   46.,   46.,   57.,   58.,   42.,   55.,\n",
       "       5997.,   49.,   27.,   32.,   57.,   44.,   43.,   37.,   43.,\n",
       "         61.,   36.,   49.,   53.,   58.,   42.,   51., 5919.,   29.,\n",
       "         52.,   60.,   44.,   40.,   51.,   34.,   56.,   45.,   40.,\n",
       "         49.,   54.,   32.,   40.,   52.,   38.,   45.,   58.,   42.,\n",
       "         45.,   50.,   53.,   53.,   70.,   34.,   33.,   58.,   74.,\n",
       "         41.,   43.,   45.,   71.,   30., 5637., 3552.,   51., 5754.,\n",
       "         46., 6103.,   34.,   41.,   48.,   40.,   40.,   44.,   43.,\n",
       "         56.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The trained model can be saved as pickle for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-239.43956  , -148.27985  , -281.3192   , ..., -142.55777  ,\n",
       "        -214.58322  , -235.33083  ],\n",
       "       [-112.88808  , -116.1815   ,  -64.24356  , ..., -132.47252  ,\n",
       "        -121.00293  ,  -22.776104 ],\n",
       "       [ -32.328655 ,  -52.749233 ,  144.76985  , ...,   21.727789 ,\n",
       "         -20.009361 , -205.19566  ],\n",
       "       ...,\n",
       "       [ -72.1823   ,  138.6279   ,   87.44407  , ...,  229.96695  ,\n",
       "          41.225166 ,   20.167723 ],\n",
       "       [  -6.853402 ,  141.3769   ,  246.19102  , ...,  153.36969  ,\n",
       "         179.23767  ,  208.78542  ],\n",
       "       [ -21.059866 ,   31.169312 ,  168.37772  , ...,   90.69682  ,\n",
       "          19.636633 ,    2.2348657]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'data/temp_model.pkl')\n",
    "\n",
    "new_model = joblib.load('data/temp_model.pkl')\n",
    "new_model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
