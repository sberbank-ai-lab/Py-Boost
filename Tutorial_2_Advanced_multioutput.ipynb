{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced options for multioutput handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# set the device to run\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from py_boost import GradientBoosting \n",
    "\n",
    "# strategies to deal with multiple outputs\n",
    "from py_boost.multioutput.sketching import *\n",
    "from py_boost.multioutput.target_splitter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-10 21:58:10--  https://www.openml.org/data/get_csv/19335692/file1c556677f875.csv\n",
      "Resolving www.openml.org (www.openml.org)... 131.155.11.11\n",
      "Connecting to www.openml.org (www.openml.org)|131.155.11.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘helena.csv’\n",
      "\n",
      "helena.csv              [        <=>         ]  14.56M  9.87MB/s    in 1.5s    \n",
      "\n",
      "2021-11-10 21:58:12 (9.87 MB/s) - ‘helena.csv’ saved [15271704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.openml.org/data/get_csv/19335692/file1c556677f875.csv -O data/helena.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.110417</td>\n",
       "      <td>0.490822</td>\n",
       "      <td>0.586406</td>\n",
       "      <td>0.066414</td>\n",
       "      <td>0.092206</td>\n",
       "      <td>0.116352</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342986</td>\n",
       "      <td>78.6894</td>\n",
       "      <td>17.237800</td>\n",
       "      <td>21.504200</td>\n",
       "      <td>14.43730</td>\n",
       "      <td>17.378000</td>\n",
       "      <td>9.61674</td>\n",
       "      <td>-0.609370</td>\n",
       "      <td>1.044830</td>\n",
       "      <td>1.481790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>0.049398</td>\n",
       "      <td>0.147917</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.542865</td>\n",
       "      <td>0.515608</td>\n",
       "      <td>0.105128</td>\n",
       "      <td>0.475550</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>0.383460</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639370</td>\n",
       "      <td>59.7879</td>\n",
       "      <td>5.393410</td>\n",
       "      <td>3.819610</td>\n",
       "      <td>11.49240</td>\n",
       "      <td>3.929470</td>\n",
       "      <td>5.91423</td>\n",
       "      <td>1.409210</td>\n",
       "      <td>4.749540</td>\n",
       "      <td>1.103820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0.548663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397029</td>\n",
       "      <td>0.627398</td>\n",
       "      <td>1.023440</td>\n",
       "      <td>1.004220</td>\n",
       "      <td>0.027381</td>\n",
       "      <td>0.451337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137427</td>\n",
       "      <td>58.1429</td>\n",
       "      <td>-3.365980</td>\n",
       "      <td>-0.037489</td>\n",
       "      <td>10.63470</td>\n",
       "      <td>2.660180</td>\n",
       "      <td>3.93377</td>\n",
       "      <td>-0.898220</td>\n",
       "      <td>2.137790</td>\n",
       "      <td>1.054470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.206250</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.622998</td>\n",
       "      <td>0.764067</td>\n",
       "      <td>0.202599</td>\n",
       "      <td>0.177892</td>\n",
       "      <td>0.071232</td>\n",
       "      <td>0.531712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477009</td>\n",
       "      <td>55.4798</td>\n",
       "      <td>-1.051090</td>\n",
       "      <td>-4.755360</td>\n",
       "      <td>13.36710</td>\n",
       "      <td>2.852060</td>\n",
       "      <td>9.65162</td>\n",
       "      <td>0.224397</td>\n",
       "      <td>-0.220216</td>\n",
       "      <td>-0.273287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>0.224427</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.902083</td>\n",
       "      <td>0.814199</td>\n",
       "      <td>0.576879</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.822975</td>\n",
       "      <td>0.026121</td>\n",
       "      <td>0.425875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521306</td>\n",
       "      <td>76.8475</td>\n",
       "      <td>-19.371700</td>\n",
       "      <td>32.270700</td>\n",
       "      <td>9.41442</td>\n",
       "      <td>4.343450</td>\n",
       "      <td>8.67710</td>\n",
       "      <td>-1.587580</td>\n",
       "      <td>1.117870</td>\n",
       "      <td>-0.545338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65191</th>\n",
       "      <td>88</td>\n",
       "      <td>0.007292</td>\n",
       "      <td>0.152083</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.114431</td>\n",
       "      <td>0.406104</td>\n",
       "      <td>0.143170</td>\n",
       "      <td>0.053086</td>\n",
       "      <td>0.129365</td>\n",
       "      <td>0.215442</td>\n",
       "      <td>...</td>\n",
       "      <td>1.265300</td>\n",
       "      <td>53.2951</td>\n",
       "      <td>-1.416430</td>\n",
       "      <td>2.173900</td>\n",
       "      <td>13.66950</td>\n",
       "      <td>1.588520</td>\n",
       "      <td>2.02855</td>\n",
       "      <td>0.619052</td>\n",
       "      <td>0.622377</td>\n",
       "      <td>-0.363035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65192</th>\n",
       "      <td>77</td>\n",
       "      <td>0.411279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.503805</td>\n",
       "      <td>0.207163</td>\n",
       "      <td>1.003740</td>\n",
       "      <td>0.412067</td>\n",
       "      <td>0.017673</td>\n",
       "      <td>0.044771</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.842380</td>\n",
       "      <td>91.1178</td>\n",
       "      <td>-0.009207</td>\n",
       "      <td>-2.224830</td>\n",
       "      <td>1.30504</td>\n",
       "      <td>0.898489</td>\n",
       "      <td>1.80362</td>\n",
       "      <td>-2.726140</td>\n",
       "      <td>-0.184329</td>\n",
       "      <td>-0.476441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65193</th>\n",
       "      <td>71</td>\n",
       "      <td>0.999352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.501360</td>\n",
       "      <td>0.501075</td>\n",
       "      <td>0.999384</td>\n",
       "      <td>0.999414</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213472</td>\n",
       "      <td>84.4141</td>\n",
       "      <td>2.042450</td>\n",
       "      <td>13.849800</td>\n",
       "      <td>7.24428</td>\n",
       "      <td>1.443890</td>\n",
       "      <td>4.00495</td>\n",
       "      <td>-0.749115</td>\n",
       "      <td>1.025130</td>\n",
       "      <td>0.096257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65194</th>\n",
       "      <td>24</td>\n",
       "      <td>0.206175</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.749915</td>\n",
       "      <td>0.550936</td>\n",
       "      <td>0.292477</td>\n",
       "      <td>0.830921</td>\n",
       "      <td>0.033542</td>\n",
       "      <td>0.430515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879472</td>\n",
       "      <td>61.4110</td>\n",
       "      <td>17.354200</td>\n",
       "      <td>5.566660</td>\n",
       "      <td>16.22600</td>\n",
       "      <td>10.049400</td>\n",
       "      <td>6.04195</td>\n",
       "      <td>0.400956</td>\n",
       "      <td>0.375599</td>\n",
       "      <td>0.644575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65195</th>\n",
       "      <td>9</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.844969</td>\n",
       "      <td>0.054704</td>\n",
       "      <td>0.091855</td>\n",
       "      <td>0.052645</td>\n",
       "      <td>0.192523</td>\n",
       "      <td>0.545068</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.676500</td>\n",
       "      <td>93.1596</td>\n",
       "      <td>0.559074</td>\n",
       "      <td>-0.852947</td>\n",
       "      <td>8.30315</td>\n",
       "      <td>1.215720</td>\n",
       "      <td>1.28395</td>\n",
       "      <td>-1.889180</td>\n",
       "      <td>2.350320</td>\n",
       "      <td>0.179997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65196 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class        V1        V2        V3        V4        V5        V6  \\\n",
       "0         41  0.005521  0.080556  0.110417  0.490822  0.586406  0.066414   \n",
       "1         92  0.049398  0.147917  0.541667  0.542865  0.515608  0.105128   \n",
       "2         24  0.548663  1.000000  1.000000  0.397029  0.627398  1.023440   \n",
       "3         29  0.023073  0.206250  0.238889  0.622998  0.764067  0.202599   \n",
       "4         91  0.224427  0.433333  0.902083  0.814199  0.576879  0.344413   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "65191     88  0.007292  0.152083  0.061111  0.114431  0.406104  0.143170   \n",
       "65192     77  0.411279  1.000000  0.430556  0.503805  0.207163  1.003740   \n",
       "65193     71  0.999352  1.000000  1.000000  0.501360  0.501075  0.999384   \n",
       "65194     24  0.206175  0.383333  0.944444  0.749915  0.550936  0.292477   \n",
       "65195      9  0.003096  0.102083  0.066667  0.844969  0.054704  0.091855   \n",
       "\n",
       "             V7        V8        V9  ...       V18      V19        V20  \\\n",
       "0      0.092206  0.116352  0.379310  ... -0.342986  78.6894  17.237800   \n",
       "1      0.475550  0.049555  0.383460  ...  2.639370  59.7879   5.393410   \n",
       "2      1.004220  0.027381  0.451337  ...  0.137427  58.1429  -3.365980   \n",
       "3      0.177892  0.071232  0.531712  ...  0.477009  55.4798  -1.051090   \n",
       "4      0.822975  0.026121  0.425875  ...  0.521306  76.8475 -19.371700   \n",
       "...         ...       ...       ...  ...       ...      ...        ...   \n",
       "65191  0.053086  0.129365  0.215442  ...  1.265300  53.2951  -1.416430   \n",
       "65192  0.412067  0.017673  0.044771  ... -2.842380  91.1178  -0.009207   \n",
       "65193  0.999414  0.009636  0.000648  ...  0.213472  84.4141   2.042450   \n",
       "65194  0.830921  0.033542  0.430515  ...  0.879472  61.4110  17.354200   \n",
       "65195  0.052645  0.192523  0.545068  ... -1.676500  93.1596   0.559074   \n",
       "\n",
       "             V21       V22        V23      V24       V25       V26       V27  \n",
       "0      21.504200  14.43730  17.378000  9.61674 -0.609370  1.044830  1.481790  \n",
       "1       3.819610  11.49240   3.929470  5.91423  1.409210  4.749540  1.103820  \n",
       "2      -0.037489  10.63470   2.660180  3.93377 -0.898220  2.137790  1.054470  \n",
       "3      -4.755360  13.36710   2.852060  9.65162  0.224397 -0.220216 -0.273287  \n",
       "4      32.270700   9.41442   4.343450  8.67710 -1.587580  1.117870 -0.545338  \n",
       "...          ...       ...        ...      ...       ...       ...       ...  \n",
       "65191   2.173900  13.66950   1.588520  2.02855  0.619052  0.622377 -0.363035  \n",
       "65192  -2.224830   1.30504   0.898489  1.80362 -2.726140 -0.184329 -0.476441  \n",
       "65193  13.849800   7.24428   1.443890  4.00495 -0.749115  1.025130  0.096257  \n",
       "65194   5.566660  16.22600  10.049400  6.04195  0.400956  0.375599  0.644575  \n",
       "65195  -0.852947   8.30315   1.215720  1.28395 -1.889180  2.350320  0.179997  \n",
       "\n",
       "[65196 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/helena.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78    4005\n",
       "55    3063\n",
       "40    2992\n",
       "39    2623\n",
       "38    2216\n",
       "      ... \n",
       "56     121\n",
       "75     121\n",
       "32     119\n",
       "34     116\n",
       "10     111\n",
       "Name: class, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like we have 100 classes here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class', axis=1).values.astype('float32')\n",
    "y = data['class'].values.astype('int32')\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train multiclass model\n",
    "\n",
    "Simple usecase for training multiclass is the same as for regression. By default py_boost builds multioutout trees to handle multioutput problems, single tree outputs a vector of length 100 for 100 class task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:09:40] Stdout logging level is INFO.\n",
      "[22:09:40] GDBT train starts. Max iter 10000, early stopping rounds 300\n",
      "[22:09:40] Iter 0; Sample 0, Crossentropy = 4.304827220079593; \n",
      "[22:09:44] Iter 100; Sample 0, Crossentropy = 2.8611263531023345; \n",
      "[22:09:49] Iter 200; Sample 0, Crossentropy = 2.728235614034673; \n",
      "[22:09:53] Iter 300; Sample 0, Crossentropy = 2.6778626299315684; \n",
      "[22:09:58] Iter 400; Sample 0, Crossentropy = 2.6502818506254036; \n",
      "[22:10:02] Iter 500; Sample 0, Crossentropy = 2.63424278326861; \n",
      "[22:10:07] Iter 600; Sample 0, Crossentropy = 2.623488614688844; \n",
      "[22:10:12] Iter 700; Sample 0, Crossentropy = 2.615064449096285; \n",
      "[22:10:16] Iter 800; Sample 0, Crossentropy = 2.6071642743631136; \n",
      "[22:10:21] Iter 900; Sample 0, Crossentropy = 2.600947677453085; \n",
      "[22:10:25] Iter 1000; Sample 0, Crossentropy = 2.596409021535033; \n",
      "[22:10:30] Iter 1100; Sample 0, Crossentropy = 2.5919130667358017; \n",
      "[22:10:35] Iter 1200; Sample 0, Crossentropy = 2.5883597160700273; \n",
      "[22:10:39] Iter 1300; Sample 0, Crossentropy = 2.5855594141815823; \n",
      "[22:10:44] Iter 1400; Sample 0, Crossentropy = 2.5831877721712835; \n",
      "[22:10:49] Iter 1500; Sample 0, Crossentropy = 2.581407835160701; \n",
      "[22:10:53] Iter 1600; Sample 0, Crossentropy = 2.5797827184382602; \n",
      "[22:10:58] Iter 1700; Sample 0, Crossentropy = 2.578892752472535; \n",
      "[22:11:02] Iter 1800; Sample 0, Crossentropy = 2.5776792918189604; \n",
      "[22:11:07] Iter 1900; Sample 0, Crossentropy = 2.5772436781295256; \n",
      "[22:11:12] Iter 2000; Sample 0, Crossentropy = 2.576366766178361; \n",
      "[22:11:16] Iter 2100; Sample 0, Crossentropy = 2.5761664769564976; \n",
      "[22:11:21] Iter 2200; Sample 0, Crossentropy = 2.575686043824722; \n",
      "[22:11:26] Iter 2300; Sample 0, Crossentropy = 2.5755712889818323; \n",
      "[22:11:30] Iter 2400; Sample 0, Crossentropy = 2.5753966259481156; \n",
      "[22:11:35] Iter 2500; Sample 0, Crossentropy = 2.575664123760991; \n",
      "[22:11:40] Iter 2600; Sample 0, Crossentropy = 2.576040000934175; \n",
      "[22:11:42] Early stopping at iter 2664, best iter 2364, best_score 2.5752600871447635\n",
      "CPU times: user 1min 46s, sys: 16.2 s, total: 2min 2s\n",
      "Wall time: 2min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7efd4b393610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = GradientBoosting('crossentropy',\n",
    "                         ntrees=10000, lr=0.03, verbose=100, es=300, lambda_l2=1,\n",
    "                         subsample=1, colsample=1, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=6)\n",
    "\n",
    "model.fit(X, y, \n",
    "          eval_sets = [{'X': X_test, 'y': y_test}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 664 ms, total: 1.83 s\n",
      "Wall time: 1.83 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13040, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sketching strategies to speedup training\n",
    "\n",
    "Training multioutput models is more time consuming than single output. That's why we implement few strategies to simplify tree structure search via gradinet matrix sketching:\n",
    "\n",
    "* ***RandomSamplingSketch*** (recommended)\n",
    "* ***TopOutputsSketch***\n",
    "* ***SVDSketch*** (needs RAPIDS (cuml) to be installed)\n",
    "\n",
    "Let's check, how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:20:12] Stdout logging level is INFO.\n",
      "[22:20:12] GDBT train starts. Max iter 10000, early stopping rounds 300\n",
      "[22:20:12] Iter 0; Sample 0, Crossentropy = 4.366729785003158; \n",
      "[22:20:14] Iter 100; Sample 0, Crossentropy = 2.900768619314183; \n",
      "[22:20:15] Iter 200; Sample 0, Crossentropy = 2.760633129321527; \n",
      "[22:20:17] Iter 300; Sample 0, Crossentropy = 2.700729209640207; \n",
      "[22:20:18] Iter 400; Sample 0, Crossentropy = 2.666901549547681; \n",
      "[22:20:20] Iter 500; Sample 0, Crossentropy = 2.6433972865472493; \n",
      "[22:20:21] Iter 600; Sample 0, Crossentropy = 2.6286164429689336; \n",
      "[22:20:23] Iter 700; Sample 0, Crossentropy = 2.6165641306630825; \n",
      "[22:20:24] Iter 800; Sample 0, Crossentropy = 2.6068343569429606; \n",
      "[22:20:26] Iter 900; Sample 0, Crossentropy = 2.598758513549033; \n",
      "[22:20:27] Iter 1000; Sample 0, Crossentropy = 2.5918135165170693; \n",
      "[22:20:29] Iter 1100; Sample 0, Crossentropy = 2.587314895990852; \n",
      "[22:20:30] Iter 1200; Sample 0, Crossentropy = 2.5825381641023717; \n",
      "[22:20:32] Iter 1300; Sample 0, Crossentropy = 2.5788432165327744; \n",
      "[22:20:33] Iter 1400; Sample 0, Crossentropy = 2.575336990250358; \n",
      "[22:20:34] Iter 1500; Sample 0, Crossentropy = 2.572204642997725; \n",
      "[22:20:36] Iter 1600; Sample 0, Crossentropy = 2.5699683562362083; \n",
      "[22:20:37] Iter 1700; Sample 0, Crossentropy = 2.5667828134886785; \n",
      "[22:20:39] Iter 1800; Sample 0, Crossentropy = 2.564760272229843; \n",
      "[22:20:40] Iter 1900; Sample 0, Crossentropy = 2.5630873508829994; \n",
      "[22:20:42] Iter 2000; Sample 0, Crossentropy = 2.562261145285589; \n",
      "[22:20:43] Iter 2100; Sample 0, Crossentropy = 2.5606403206776185; \n",
      "[22:20:45] Iter 2200; Sample 0, Crossentropy = 2.559498953233662; \n",
      "[22:20:46] Iter 2300; Sample 0, Crossentropy = 2.55851029410001; \n",
      "[22:20:47] Iter 2400; Sample 0, Crossentropy = 2.5579752873822352; \n",
      "[22:20:49] Iter 2500; Sample 0, Crossentropy = 2.557269243058043; \n",
      "[22:20:51] Iter 2600; Sample 0, Crossentropy = 2.55709386653872; \n",
      "[22:20:52] Iter 2700; Sample 0, Crossentropy = 2.5569531985693255; \n",
      "[22:20:53] Iter 2800; Sample 0, Crossentropy = 2.5570778148606164; \n",
      "[22:20:55] Iter 2900; Sample 0, Crossentropy = 2.556838185788999; \n",
      "[22:20:56] Iter 3000; Sample 0, Crossentropy = 2.557360188507153; \n",
      "[22:20:57] Early stopping at iter 3027, best iter 2727, best_score 2.5567850348825933\n",
      "CPU times: user 42.6 s, sys: 2.37 s, total: 45 s\n",
      "Wall time: 44.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7efd18392880>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sketch = RandomSamplingSketch(10)\n",
    "\n",
    "model = GradientBoosting('crossentropy',\n",
    "                         ntrees=10000, lr=0.03, verbose=100, es=300, lambda_l2=1,\n",
    "                         subsample=1, colsample=1, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=6,\n",
    "                         multioutput_sketch=sketch\n",
    "                        )\n",
    "\n",
    "model.fit(X, y, eval_sets = [{'X': X_test, 'y': y_test}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13040, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nice speed up and some times even better accuracy !\n",
    "\n",
    "#### Its even faster than catboost with close to the same setup :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.2940514\ttest: 4.3045907\tbest: 4.3045907 (0)\ttotal: 44.4ms\tremaining: 7m 24s\n",
      "100:\tlearn: 2.7026061\ttest: 2.8639819\tbest: 2.8639819 (100)\ttotal: 3.76s\tremaining: 6m 8s\n",
      "200:\tlearn: 2.4526127\ttest: 2.7287550\tbest: 2.7287550 (200)\ttotal: 7.26s\tremaining: 5m 54s\n",
      "300:\tlearn: 2.3213709\ttest: 2.6789284\tbest: 2.6789284 (300)\ttotal: 10.6s\tremaining: 5m 42s\n",
      "400:\tlearn: 2.2232475\ttest: 2.6516266\tbest: 2.6516266 (400)\ttotal: 13.9s\tremaining: 5m 33s\n",
      "500:\tlearn: 2.1449561\ttest: 2.6351179\tbest: 2.6351179 (500)\ttotal: 17.1s\tremaining: 5m 25s\n",
      "600:\tlearn: 2.0773091\ttest: 2.6237368\tbest: 2.6237368 (600)\ttotal: 20.3s\tremaining: 5m 17s\n",
      "700:\tlearn: 2.0146066\ttest: 2.6149354\tbest: 2.6149321 (699)\ttotal: 23.5s\tremaining: 5m 11s\n",
      "800:\tlearn: 1.9531132\ttest: 2.6072940\tbest: 2.6072841 (799)\ttotal: 26.6s\tremaining: 5m 5s\n",
      "900:\tlearn: 1.8969742\ttest: 2.6016194\tbest: 2.6016194 (900)\ttotal: 29.8s\tremaining: 5m 1s\n",
      "1000:\tlearn: 1.8410815\ttest: 2.5963370\tbest: 2.5963370 (1000)\ttotal: 33s\tremaining: 4m 56s\n",
      "1100:\tlearn: 1.7884031\ttest: 2.5926045\tbest: 2.5926045 (1100)\ttotal: 36.2s\tremaining: 4m 52s\n",
      "1200:\tlearn: 1.7363575\ttest: 2.5891224\tbest: 2.5891224 (1200)\ttotal: 39.3s\tremaining: 4m 48s\n",
      "1300:\tlearn: 1.6876309\ttest: 2.5862320\tbest: 2.5862320 (1300)\ttotal: 42.5s\tremaining: 4m 43s\n",
      "1400:\tlearn: 1.6391251\ttest: 2.5840856\tbest: 2.5840497 (1399)\ttotal: 45.6s\tremaining: 4m 40s\n",
      "1500:\tlearn: 1.5954440\ttest: 2.5822577\tbest: 2.5822577 (1500)\ttotal: 48.7s\tremaining: 4m 35s\n",
      "1600:\tlearn: 1.5487287\ttest: 2.5805577\tbest: 2.5805143 (1596)\ttotal: 51.9s\tremaining: 4m 32s\n",
      "1700:\tlearn: 1.5048332\ttest: 2.5793175\tbest: 2.5793175 (1700)\ttotal: 55s\tremaining: 4m 28s\n",
      "1800:\tlearn: 1.4619290\ttest: 2.5782481\tbest: 2.5781924 (1796)\ttotal: 58.2s\tremaining: 4m 24s\n",
      "1900:\tlearn: 1.4215622\ttest: 2.5770451\tbest: 2.5770088 (1895)\ttotal: 1m 1s\tremaining: 4m 21s\n",
      "2000:\tlearn: 1.3810523\ttest: 2.5762941\tbest: 2.5762941 (2000)\ttotal: 1m 4s\tremaining: 4m 17s\n",
      "2100:\tlearn: 1.3412729\ttest: 2.5753265\tbest: 2.5753265 (2100)\ttotal: 1m 7s\tremaining: 4m 14s\n",
      "2200:\tlearn: 1.3069094\ttest: 2.5754077\tbest: 2.5752642 (2111)\ttotal: 1m 10s\tremaining: 4m 10s\n",
      "2300:\tlearn: 1.2680846\ttest: 2.5749533\tbest: 2.5749107 (2292)\ttotal: 1m 13s\tremaining: 4m 7s\n",
      "2400:\tlearn: 1.2329422\ttest: 2.5745540\tbest: 2.5745087 (2393)\ttotal: 1m 17s\tremaining: 4m 3s\n",
      "2500:\tlearn: 1.1996894\ttest: 2.5750623\tbest: 2.5744347 (2440)\ttotal: 1m 20s\tremaining: 4m\n",
      "2600:\tlearn: 1.1656658\ttest: 2.5749584\tbest: 2.5744347 (2440)\ttotal: 1m 23s\tremaining: 3m 56s\n",
      "2700:\tlearn: 1.1336638\ttest: 2.5751600\tbest: 2.5744347 (2440)\ttotal: 1m 26s\tremaining: 3m 53s\n",
      "bestTest = 2.574434732\n",
      "bestIteration = 2440\n",
      "Shrink model to first 2441 iterations.\n",
      "CPU times: user 2min 52s, sys: 39.9 s, total: 3min 32s\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7efd1837f970>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "                       grow_policy='Depthwise', \n",
    "                       bootstrap_type='Bernoulli',\n",
    "                       subsample=1.,\n",
    "                       border_count=256, \n",
    "                       iterations=10000, \n",
    "                       od_wait=300,\n",
    "                       max_depth=6, \n",
    "                       devices='0:0', \n",
    "                       learning_rate=0.03, \n",
    "                       l2_leaf_reg=1, \n",
    "                       min_data_in_leaf=10, \n",
    "                       score_function='L2',\n",
    "                       model_shrink_mode='Constant',\n",
    "                       **{'task_type': 'GPU', 'verbose': 100, }\n",
    "                    )\n",
    "\n",
    "model.fit(X, y, eval_set = (X_test, y_test))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target splitting strategies\n",
    "\n",
    "As it was mentioned above, py_boost builds a single tree for all outputs. Commonly its recommended strategy, but there are some options. Here are possible strategies:\n",
    "\n",
    "* ***'Single'*** stands for default strategy\n",
    "* ***'OneVsAll'*** (not recommended) stands for building separate trees for the each output\n",
    "* ***RandomGroupsSplitter*** (experimental) randomly groups the outputs at the each iteration and build a tree per group. For example, you can build 3 trees predicting 100 classes\n",
    "* ***Custom*** build your own strategy to split outputs to the groups\n",
    "\n",
    "#### Now, let's try to check RandomGroupsSplitter together with the sketching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:46:05] Stdout logging level is INFO.\n",
      "[22:46:05] GDBT train starts. Max iter 10000, early stopping rounds 300\n",
      "[22:46:06] Iter 0; Sample 0, Crossentropy = 4.326980387631079; \n",
      "[22:46:09] Iter 100; Sample 0, Crossentropy = 2.8532873930758953; \n",
      "[22:46:13] Iter 200; Sample 0, Crossentropy = 2.7270546642112574; \n",
      "[22:46:17] Iter 300; Sample 0, Crossentropy = 2.67468653221888; \n",
      "[22:46:21] Iter 400; Sample 0, Crossentropy = 2.646447996475138; \n",
      "[22:46:25] Iter 500; Sample 0, Crossentropy = 2.6275378505210005; \n",
      "[22:46:29] Iter 600; Sample 0, Crossentropy = 2.614286675159497; \n",
      "[22:46:33] Iter 700; Sample 0, Crossentropy = 2.6037103730812103; \n",
      "[22:46:38] Iter 800; Sample 0, Crossentropy = 2.596234914516479; \n",
      "[22:46:42] Iter 900; Sample 0, Crossentropy = 2.5894875879047965; \n",
      "[22:46:46] Iter 1000; Sample 0, Crossentropy = 2.584543545871069; \n",
      "[22:46:50] Iter 1100; Sample 0, Crossentropy = 2.5801520899776977; \n",
      "[22:46:54] Iter 1200; Sample 0, Crossentropy = 2.57597971092585; \n",
      "[22:46:58] Iter 1300; Sample 0, Crossentropy = 2.5725311515987053; \n",
      "[22:47:02] Iter 1400; Sample 0, Crossentropy = 2.5694662048260937; \n",
      "[22:47:06] Iter 1500; Sample 0, Crossentropy = 2.567306610993608; \n",
      "[22:47:10] Iter 1600; Sample 0, Crossentropy = 2.5654212548491846; \n",
      "[22:47:14] Iter 1700; Sample 0, Crossentropy = 2.56361714201889; \n",
      "[22:47:18] Iter 1800; Sample 0, Crossentropy = 2.562442278998529; \n",
      "[22:47:22] Iter 1900; Sample 0, Crossentropy = 2.5613982175347605; \n",
      "[22:47:26] Iter 2000; Sample 0, Crossentropy = 2.5609817547010025; \n",
      "[22:47:30] Iter 2100; Sample 0, Crossentropy = 2.560376741309913; \n",
      "[22:47:34] Iter 2200; Sample 0, Crossentropy = 2.5600201235618623; \n",
      "[22:47:38] Iter 2300; Sample 0, Crossentropy = 2.559734787537352; \n",
      "[22:47:42] Iter 2400; Sample 0, Crossentropy = 2.559686976391944; \n",
      "[22:47:46] Iter 2500; Sample 0, Crossentropy = 2.5602813772520476; \n",
      "[22:47:49] Early stopping at iter 2565, best iter 2265, best_score 2.559590334390923\n",
      "CPU times: user 1min 39s, sys: 4.38 s, total: 1min 43s\n",
      "Wall time: 1min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<py_boost.gpu.boosting.GradientBoosting at 0x7efb850701c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "splitter = RandomGroupsSplitter(3)\n",
    "sketch = RandomSamplingSketch(10)\n",
    "\n",
    "model = GradientBoosting('crossentropy',\n",
    "                         ntrees=10000, lr=0.03, verbose=100, es=300, lambda_l2=1,\n",
    "                         subsample=1, colsample=1, min_data_in_leaf=10,\n",
    "                         max_bin=256, max_depth=6,\n",
    "                         multioutput_sketch=sketch,\n",
    "                         target_splitter=splitter\n",
    "                        )\n",
    "\n",
    "model.fit(X, y, eval_sets = [{'X': X_test, 'y': y_test}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Didn't improve the score, but at least we could try :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
